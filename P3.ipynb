{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b5a8944-f099-46dc-bf53-663b847b2f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadind Dataset: gestures\n",
      "3251 samples loaded\n",
      "Scaling Dataset: gestures\n",
      "3251 samples scaled\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Loadind Dataset: gestures\")\n",
    "path = 'gestures-dataset'\n",
    "\n",
    "dataset = None\n",
    "dataset_idx = None\n",
    "samples = 0\n",
    "for subject in os.listdir(path):\n",
    "    if os.path.isfile(os.path.join(path, subject)):\n",
    "        continue\n",
    "    if subject in ('U01', 'U02', 'U03', 'U04', 'U05', 'U06', 'U07', 'U08'):\n",
    "        for gesture in os.listdir(os.path.join(path, subject)):\n",
    "            if os.path.isfile(os.path.join(path, subject, gesture)):\n",
    "                continue\n",
    "            gesture = str(gesture)\n",
    "            #if gesture not in gesture_subset:\n",
    "            #    continue\n",
    "            for samplefile in os.listdir(os.path.join(path, subject, gesture)):\n",
    "                if os.path.isfile(os.path.join(path, subject, gesture, samplefile)):\n",
    "                    df = pd.read_csv(os.path.join(path, subject, gesture, samplefile), \\\n",
    "                        sep = ' ', \\\n",
    "                        names = ['System.currentTimeMillis()', \\\n",
    "                        'System.nanoTime()', \\\n",
    "                        'sample.timestamp', \\\n",
    "                        'X', \\\n",
    "                        'Y', \\\n",
    "                        'Z' \\\n",
    "                        ])\n",
    "                    df = df[[\"sample.timestamp\", \"X\", \"Y\", \"Z\"]]\n",
    "                                        \n",
    "                    start = df[\"sample.timestamp\"][0]\n",
    "                    df[\"sample.timestamp\"] -= start\n",
    "                    df[\"sample.timestamp\"] /= 10000000\n",
    "                    df[\"subject\"] = subject\n",
    "                    df[\"gesture\"] = gesture\n",
    "                    df[\"sample\"] = str(samplefile[:-4])\n",
    "                    #print(df)\n",
    "                    if dataset is None:\n",
    "                        dataset = df.copy()\n",
    "                    else:\n",
    "                        dataset = pd.concat([dataset, df])\n",
    "\n",
    "                    df_idx_sample = pd.DataFrame()\n",
    "                    df_idx_sample = df_idx_sample.append({'subject':subject, 'gesture': gesture, 'sample': str(samplefile[:-4])}, ignore_index = True)\n",
    "                    if dataset_idx is None:\n",
    "                        dataset_idx = df_idx_sample.copy()\n",
    "                    else:\n",
    "                        dataset_idx = pd.concat([dataset_idx, df_idx_sample])\n",
    "                    samples += 1\n",
    "\n",
    "dataset = dataset.sort_values(by=['gesture','subject','sample','sample.timestamp'])\n",
    "dataset_idx = dataset_idx.sort_values(by=['gesture','subject','sample'])\n",
    "data = dataset  \n",
    "print(str(samples) + \" samples loaded\")\n",
    "\n",
    "print(\"Scaling Dataset: gestures\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dataset_scaled = None\n",
    "samples = 0\n",
    "#for i, gesture in enumerate(gesture_subset):\n",
    "for i, gesture in enumerate(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']):\n",
    "    df_gesture=data[data['gesture']==gesture] \n",
    "    for j, subject in enumerate(df_gesture['subject'].unique()):\n",
    "        df_subject=df_gesture[df_gesture['subject']==subject]\n",
    "        for k, sample in enumerate(df_subject['sample'].unique()):\n",
    "            df_sample=df_subject[df_subject['sample']==sample].copy()\n",
    "            df_sample.sort_values(by=['sample.timestamp'])\n",
    "\n",
    "            sc = scaler\n",
    "            sc = sc.fit_transform(df_sample[[\"X\", \"Y\", \"Z\"]])\n",
    "            sc = pd.DataFrame(data=sc, columns=[\"X\", \"Y\", \"Z\"])\n",
    "            df_sample['X'] = sc['X']\n",
    "            df_sample['Y'] = sc['Y']\n",
    "            df_sample['Z'] = sc['Z']\n",
    "            if dataset_scaled is None:\n",
    "                dataset_scaled = df_sample.copy()\n",
    "            else:\n",
    "                dataset_scaled = pd.concat([dataset_scaled, df_sample])\n",
    "            samples += 1\n",
    "print(str(samples) + \" samples scaled\")\n",
    "data = dataset_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4407d4bb-c6bc-4b02-bfa5-f2bc7191d481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting All Features as describe in features.json, total of 384, 128 per axis: dataset_scaled\n",
      "Set: 64070 measurements\n",
      "Features extracted from 3251 samples\n"
     ]
    }
   ],
   "source": [
    "import tsfel\n",
    "\n",
    "cfg_file = tsfel.get_features_by_domain(domain=None, json_path=\"features.json\")\n",
    "#cfg_file = tsfel.get_features_by_domain(\"statistical\")\n",
    "#cfg_file = tsfel.get_features_by_domain(\"temporal\")\n",
    "#cgf_file = tsfel.get_features_by_domain(\"spectral\")\n",
    "\n",
    "print(\"Extracting All Features as describe in features.json, total of 384, 128 per axis: dataset_scaled\")\n",
    "data = dataset_scaled\n",
    "print(\"Set: \" + str(len(data.index)) + \" measurements\")\n",
    "dataset_features = None\n",
    "samples = 0\n",
    "for i, gesture in enumerate(data['gesture'].unique()):\n",
    "    df_gesture = data[data['gesture']==gesture]\n",
    "    for j, subject in enumerate(df_gesture['subject'].unique()):\n",
    "        df_subject = df_gesture[df_gesture['subject']==subject]\n",
    "        for k, sample in enumerate(df_subject['sample'].unique()):\n",
    "            df_sample = df_subject[df_subject['sample']==sample]\n",
    "            df_sample.sort_values(by=['sample.timestamp'])\n",
    "\n",
    "            df_feature = pd.DataFrame(columns = [\"gesture\",\"subject\", \"sample\"])\n",
    "            #print(df_sample[\"Y\"].size)\n",
    "            df_feature = df_feature.append({ \\\n",
    "                                        'gesture' :gesture, 'subject' : subject, 'sample' : sample, \\\n",
    "                                        'features': pd.concat( \\\n",
    "                                            [\n",
    "                                                tsfel.time_series_features_extractor(cfg_file, df_sample[\"X\"], fs=1000, verbose=0), \\\n",
    "                                                tsfel.time_series_features_extractor(cfg_file, df_sample[\"Y\"], fs=1000, verbose=0), \\\n",
    "                                                tsfel.time_series_features_extractor(cfg_file, df_sample[\"Z\"], fs=1000, verbose=0)  \\\n",
    "                                            ], axis = 1) \\\n",
    "                                       }, \\\n",
    "                                       ignore_index=True)\n",
    "            if dataset_features is None:\n",
    "                dataset_features = df_feature.copy()\n",
    "            else:\n",
    "                dataset_features = pd.concat([dataset_features, df_feature], ignore_index=True)\n",
    "            samples += 1\n",
    "#print(dataset_features.head(10))\n",
    "#print(dataset_features.tail(10))\n",
    "print(\"Features extracted from \" + str(samples) + \" samples\")\n",
    "dataset_scaled_features = dataset_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25db29bf-ad41-40cd-9ae6-59860e8aaad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segregating outliers for testing separately: gestures\n",
      "2479 samples cleaned\n",
      "772 samples outliers\n"
     ]
    }
   ],
   "source": [
    "print(\"Segregating outliers for testing separately: gestures\")\n",
    "data = dataset_scaled\n",
    "dataset_outliers = None\n",
    "dataset_outliers_idx = None\n",
    "dataset_cleaned = None\n",
    "dataset_cleaned_idx = None\n",
    "\n",
    "samples = 0\n",
    "outliers = 0\n",
    "#for i, gesture in enumerate(gesture_subset):\n",
    "for i, gesture in enumerate(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']):\n",
    "    df_gesture = data[data['gesture']==gesture]\n",
    "    for j, subject in enumerate(df_gesture['subject'].unique()):\n",
    "        df_subject = df_gesture[df_gesture['subject']==subject]\n",
    "        \n",
    "        time_mean = df_subject.groupby([\"gesture\",\"subject\", \"sample\"]).count().groupby([\"gesture\",\"subject\"]).agg({'sample.timestamp': ['mean']})\n",
    "        time_std = df_subject.groupby([\"gesture\",\"subject\", \"sample\"]).count().groupby([\"gesture\",\"subject\"]).agg({'sample.timestamp': ['std']})\n",
    "        time_max = time_mean['sample.timestamp'].iloc[0]['mean'] + 1.0 * time_std['sample.timestamp'].iloc[0]['std']\n",
    "        time_min = time_mean['sample.timestamp'].iloc[0]['mean'] - 1.0 * time_std['sample.timestamp'].iloc[0]['std']\n",
    "        for k, sample in enumerate(df_subject['sample'].unique()):\n",
    "            df_sample=df_subject[df_subject['sample']==sample]\n",
    "            df_sample_count = df_sample.count()['sample.timestamp']\n",
    "            if df_sample_count < time_min or df_sample_count > time_max:\n",
    "                if dataset_outliers is None:\n",
    "                    dataset_outliers = df_sample.copy()\n",
    "                else:\n",
    "                    dataset_outliers = pd.concat([dataset_outliers, df_sample])\n",
    "                df_idx_sample = pd.DataFrame()\n",
    "                df_idx_sample = df_idx_sample.append({'subject':subject, 'gesture': gesture, 'sample': sample}, ignore_index = True)\n",
    "                if dataset_outliers_idx is None:\n",
    "                    dataset_outliers_idx = df_idx_sample.copy()\n",
    "                else:\n",
    "                    dataset_outliers_idx = pd.concat([dataset_outliers_idx, df_idx_sample])\n",
    "                outliers += 1\n",
    "            else:\n",
    "                if dataset_cleaned is None:\n",
    "                    dataset_cleaned = df_sample.copy()\n",
    "                else:\n",
    "                    dataset_cleaned = pd.concat([dataset_cleaned, df_sample])\n",
    "                df_idx_sample = pd.DataFrame()\n",
    "                df_idx_sample = df_idx_sample.append({'subject':subject, 'gesture': gesture, 'sample': sample}, ignore_index = True)\n",
    "                if dataset_cleaned_idx is None:\n",
    "                    dataset_cleaned_idx = df_idx_sample.copy()\n",
    "                else:\n",
    "                    dataset_cleaned_idx = pd.concat([dataset_cleaned_idx, df_idx_sample])\n",
    "                samples += 1\n",
    "print(str(samples) + \" samples cleaned\")\n",
    "print(str(outliers) + \" samples outliers\")\n",
    "data = dataset_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6fca8b-8e56-4457-b0bf-85c1fba99213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segregating a stratified test set in addition to outliers: gestures\n",
      "Training set: 2107 samples\n",
      "Test set: 372 samples\n"
     ]
    }
   ],
   "source": [
    "print(\"Segregating a stratified test set in addition to outliers: gestures\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = dataset_cleaned_idx\n",
    "train, test = train_test_split(data, test_size=0.15, train_size=0.85, random_state=1000, shuffle=True, stratify=data['gesture'])\n",
    "print(\"Training set: \" + str(len(train.index)) + \" samples\")\n",
    "print(\"Test set: \" + str(len(test.index)) + \" samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8888f26f-1152-4117-b555-0e54f0d408fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling training samples with measurement data\n",
      "2107 training samples filled\n",
      "Filling test samples with measurement data\n",
      "372 test samples filled\n"
     ]
    }
   ],
   "source": [
    "print(\"Filling training samples with measurement data\")\n",
    "data = dataset_cleaned\n",
    "dataset_cleaned_train = None\n",
    "samples = 0\n",
    "for tmp in train.iterrows():\n",
    "    df = data[data['gesture'] == tmp[1]['gesture']]\n",
    "    df = df[df['subject'] == tmp[1]['subject']]\n",
    "    df = df[df['sample'] == tmp[1]['sample']]\n",
    "    if dataset_cleaned_train is None:\n",
    "        dataset_cleaned_train = df.copy()\n",
    "    else:\n",
    "        dataset_cleaned_train = pd.concat([dataset_cleaned_train, df])\n",
    "    samples += 1\n",
    "print(str(samples) + \" training samples filled\")\n",
    "\n",
    "print(\"Filling test samples with measurement data\")\n",
    "data = dataset_cleaned\n",
    "dataset_cleaned_test = None\n",
    "samples = 0\n",
    "for tmp in test.iterrows():\n",
    "    df = data[data['gesture'] == tmp[1]['gesture']]\n",
    "    df = df[df['subject'] == tmp[1]['subject']]\n",
    "    df = df[df['sample'] == tmp[1]['sample']]\n",
    "    if dataset_cleaned_test is None:\n",
    "        dataset_cleaned_test = df.copy()\n",
    "    else:\n",
    "        dataset_cleaned_test = pd.concat([dataset_cleaned_test, df])\n",
    "    samples += 1\n",
    "print(str(samples) + \" test samples filled\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe096e79-5a8d-45c1-a861-c773b68b62e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling training samples with features data\n",
      "2107 training samples filled\n",
      "Filling test samples with feature data\n",
      "372 test samples filled\n",
      "Filling outliers samples with feature data\n",
      "772 outliers samples filled\n"
     ]
    }
   ],
   "source": [
    "print(\"Filling training samples with features data\")\n",
    "data = dataset_scaled_features\n",
    "dataset_cleaned_train_features = None\n",
    "samples = 0\n",
    "for tmp in train.iterrows():\n",
    "    df = data[data['gesture'] == tmp[1]['gesture']]\n",
    "    df = df[df['subject'] == tmp[1]['subject']]\n",
    "    df = df[df['sample'] == tmp[1]['sample']]\n",
    "    if dataset_cleaned_train_features is None:\n",
    "        dataset_cleaned_train_features = df.copy()\n",
    "    else:\n",
    "        dataset_cleaned_train_features = pd.concat([dataset_cleaned_train_features, df])\n",
    "    samples += 1\n",
    "print(str(samples) + \" training samples filled\")\n",
    "\n",
    "print(\"Filling test samples with feature data\")\n",
    "data = dataset_scaled_features\n",
    "dataset_cleaned_test_features = None\n",
    "samples = 0\n",
    "for tmp in test.iterrows():\n",
    "    df = data[data['gesture'] == tmp[1]['gesture']]\n",
    "    df = df[df['subject'] == tmp[1]['subject']]\n",
    "    df = df[df['sample'] == tmp[1]['sample']]\n",
    "    if dataset_cleaned_test_features is None:\n",
    "        dataset_cleaned_test_features = df.copy()\n",
    "    else:\n",
    "        dataset_cleaned_test_features = pd.concat([dataset_cleaned_test_features, df])\n",
    "    samples += 1\n",
    "print(str(samples) + \" test samples filled\")\n",
    "\n",
    "print(\"Filling outliers samples with feature data\")\n",
    "data = dataset_scaled_features\n",
    "dataset_outliers_features = None\n",
    "samples = 0\n",
    "for tmp in dataset_outliers_idx.iterrows():\n",
    "    df = data[data['gesture'] == tmp[1]['gesture']]\n",
    "    df = df[df['subject'] == tmp[1]['subject']]\n",
    "    df = df[df['sample'] == tmp[1]['sample']]\n",
    "    if dataset_cleaned_test_features is None:\n",
    "        dataset_outliers_features = df.copy()\n",
    "    else:\n",
    "        dataset_outliers_features = pd.concat([dataset_outliers_features, df])\n",
    "    samples += 1\n",
    "print(str(samples) + \" outliers samples filled\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cfb2b76-0ee2-419f-ba27-66baff496319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               features\n",
      "220      0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "610      0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "293      0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "2776     0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "2183     0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "...                                                 ...\n",
      "622      0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "705      0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "1972     0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "1007     0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "820      0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "\n",
      "[2107 rows x 1 columns]\n",
      "                                               features\n",
      "851      0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "3162     0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "701      0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "1788     0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "1534     0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "...                                                 ...\n",
      "1892     0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "1        0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "3187     0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "172      0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "2215     0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "\n",
      "[372 rows x 1 columns]\n",
      "                                               features\n",
      "6        0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "13       0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "20       0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "27       0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "29       0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "...                                                 ...\n",
      "3225     0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "3226     0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "3233     0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "3242     0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "3248     0_FFT mean coefficient_0  0_FFT mean coeffi...\n",
      "\n",
      "[772 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "data = dataset_cleaned_train_features\n",
    "work = data.copy()\n",
    "work = work.drop(labels = [\"gesture\",\"subject\", \"sample\"], axis = 1)\n",
    "work = pd.DataFrame(work['features'])\n",
    "print(work)\n",
    "\n",
    "data = dataset_cleaned_test_features\n",
    "work = data.copy()\n",
    "work = work.drop(labels = [\"gesture\",\"subject\", \"sample\"], axis = 1)\n",
    "work = pd.DataFrame(work['features'])\n",
    "print(work)\n",
    "\n",
    "data = dataset_outliers_features\n",
    "work = data.copy()\n",
    "work = work.drop(labels = [\"gesture\",\"subject\", \"sample\"], axis = 1)\n",
    "work = pd.DataFrame(work['features'])\n",
    "print(work)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02010474-3e12-4917-99f2-30bbd512d8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0_FFT mean coefficient_0  0_FFT mean coefficient_1  \\\n",
      "  0              4.242484e-07                  0.001894\n",
      "\n",
      "     0_FFT mean coefficient_2  0_FFT mean coefficient_3  \\\n",
      "  0                  0.004739                  0.002492\n",
      "\n",
      "     0_FFT mean coefficient_4  0_FFT mean coefficient_5  \\\n",
      "  0                  0.001713                  0.002415\n",
      "\n",
      "     0_FFT mean coefficient_6  0_Fundamental frequency  0_Human range energy  \\\n",
      "  0                  0.000964                    200.0                   0.0\n",
      "\n",
      "      0_MFCC_0  ...  0_Median diff  0_Negative turning points  \\\n",
      "  0 -73.168379  ...      -0.018173                        2.0\n",
      "\n",
      "     0_Neighbourhood peaks  0_Peak to peak distance  0_Positive turning points  \\\n",
      "  0                    0.0                  3.90732                        3.0\n",
      "\n",
      "     0_Signal distance   0_Slope  0_Sum absolute diff  0_Total energy  \\\n",
      "  0          16.792881 -0.080256             8.069069     1090.909091\n",
      "\n",
      "     0_Zero crossing rate\n",
      "  0                   2.0\n",
      "\n",
      "  [1 rows x 384 columns]                                                         ]\n",
      " [   0_FFT mean coefficient_0  0_FFT mean coefficient_1  \\\n",
      "  0                  0.000393                  0.009256\n",
      "\n",
      "     0_FFT mean coefficient_2  0_FFT mean coefficient_3  \\\n",
      "  0                  0.003089                  0.000003\n",
      "\n",
      "     0_FFT mean coefficient_4  0_FFT mean coefficient_5  \\\n",
      "  0                  0.000172                  0.000015\n",
      "\n",
      "     0_FFT mean coefficient_6  0_FFT mean coefficient_7  \\\n",
      "  0                  0.000027                  0.000038\n",
      "\n",
      "     0_FFT mean coefficient_8  0_Fundamental frequency  ...  0_Median diff  \\\n",
      "  0                  0.000037                71.428571  ...       0.033832\n",
      "\n",
      "     0_Negative turning points  0_Neighbourhood peaks  0_Peak to peak distance  \\\n",
      "  0                        2.0                    0.0                 3.450844\n",
      "\n",
      "     0_Positive turning points  0_Signal distance   0_Slope  \\\n",
      "  0                        3.0          18.686331  0.054313\n",
      "\n",
      "     0_Sum absolute diff  0_Total energy  0_Zero crossing rate\n",
      "  0             7.815146          1062.5                   6.0\n",
      "\n",
      "  [1 rows x 390 columns]                                                         ]\n",
      " [   0_FFT mean coefficient_0  0_FFT mean coefficient_1  \\\n",
      "  0                  0.000134                  0.008791\n",
      "\n",
      "     0_FFT mean coefficient_2  0_FFT mean coefficient_3  \\\n",
      "  0                  0.004305                  0.002573\n",
      "\n",
      "     0_FFT mean coefficient_4  0_FFT mean coefficient_5  \\\n",
      "  0                  0.000203                  0.000416\n",
      "\n",
      "     0_FFT mean coefficient_6  0_FFT mean coefficient_7  \\\n",
      "  0                  0.000834                   0.00013\n",
      "\n",
      "     0_FFT mean coefficient_8  0_Fundamental frequency  ...  0_Median diff  \\\n",
      "  0                  0.000151                71.428571  ...      -0.900427\n",
      "\n",
      "     0_Negative turning points  0_Neighbourhood peaks  0_Peak to peak distance  \\\n",
      "  0                        4.0                    0.0                 3.601705\n",
      "\n",
      "     0_Positive turning points  0_Signal distance   0_Slope  \\\n",
      "  0                        5.0          25.486459  0.065546\n",
      "\n",
      "     0_Sum absolute diff  0_Total energy  0_Zero crossing rate\n",
      "  0            19.809385     1066.666667                   9.0\n",
      "\n",
      "  [1 rows x 390 columns]                                                         ]\n",
      " ...\n",
      " [   0_FFT mean coefficient_0  0_FFT mean coefficient_1  \\\n",
      "  0                   0.00027                  0.012401\n",
      "\n",
      "     0_FFT mean coefficient_2  0_FFT mean coefficient_3  \\\n",
      "  0                  0.000454                  0.001414\n",
      "\n",
      "     0_FFT mean coefficient_4  0_FFT mean coefficient_5  \\\n",
      "  0                  0.001394                  0.000046\n",
      "\n",
      "     0_FFT mean coefficient_6  0_FFT mean coefficient_7  \\\n",
      "  0                  0.000143              4.493547e-08\n",
      "\n",
      "     0_FFT mean coefficient_8  0_Fundamental frequency  ...  0_Median diff  \\\n",
      "  0                  0.000003                71.428571  ...       0.073079\n",
      "\n",
      "     0_Negative turning points  0_Neighbourhood peaks  0_Peak to peak distance  \\\n",
      "  0                        3.0                    0.0                 3.653959\n",
      "\n",
      "     0_Positive turning points  0_Signal distance   0_Slope  \\\n",
      "  0                        4.0          21.223853  0.022139\n",
      "\n",
      "     0_Sum absolute diff  0_Total energy  0_Zero crossing rate\n",
      "  0            13.775424     1066.666667                   3.0\n",
      "\n",
      "  [1 rows x 390 columns]                                                         ]\n",
      " [   0_FFT mean coefficient_0  0_FFT mean coefficient_1  \\\n",
      "  0              3.967291e-07                  0.005888\n",
      "\n",
      "     0_FFT mean coefficient_2  0_FFT mean coefficient_3  \\\n",
      "  0                  0.013868                  0.002099\n",
      "\n",
      "     0_FFT mean coefficient_4  0_FFT mean coefficient_5  \\\n",
      "  0                  0.000225                  0.003229\n",
      "\n",
      "     0_FFT mean coefficient_6  0_FFT mean coefficient_7  \\\n",
      "  0                  0.000967                  0.001768\n",
      "\n",
      "     0_FFT mean coefficient_8  0_FFT mean coefficient_9  ...  0_Median diff  \\\n",
      "  0                  0.002106                  0.000002  ...      -0.088698\n",
      "\n",
      "     0_Negative turning points  0_Neighbourhood peaks  0_Peak to peak distance  \\\n",
      "  0                        5.0                    1.0                  4.70097\n",
      "\n",
      "     0_Positive turning points  0_Signal distance   0_Slope  \\\n",
      "  0                        6.0          36.758504 -0.024097\n",
      "\n",
      "     0_Sum absolute diff  0_Total energy  0_Zero crossing rate\n",
      "  0            22.499611          1040.0                   8.0\n",
      "\n",
      "  [1 rows x 405 columns]                                                         ]\n",
      " [   0_FFT mean coefficient_0  0_FFT mean coefficient_1  \\\n",
      "  0                  0.000089                  0.000888\n",
      "\n",
      "     0_FFT mean coefficient_2  0_FFT mean coefficient_3  \\\n",
      "  0                   0.00514                  0.004715\n",
      "\n",
      "     0_FFT mean coefficient_4  0_FFT mean coefficient_5  \\\n",
      "  0                  0.001694                  0.000337\n",
      "\n",
      "     0_FFT mean coefficient_6  0_FFT mean coefficient_7  \\\n",
      "  0                  0.003286                  0.000406\n",
      "\n",
      "     0_FFT mean coefficient_8  0_FFT mean coefficient_9  ...  0_Median diff  \\\n",
      "  0                  0.002249                  0.003717  ...      -0.029278\n",
      "\n",
      "     0_Negative turning points  0_Neighbourhood peaks  0_Peak to peak distance  \\\n",
      "  0                        3.0                    0.0                 3.981872\n",
      "\n",
      "     0_Positive turning points  0_Signal distance   0_Slope  \\\n",
      "  0                        4.0          25.140584  0.004051\n",
      "\n",
      "     0_Sum absolute diff  0_Total energy  0_Zero crossing rate\n",
      "  0             12.79469     1052.631579                   4.0\n",
      "\n",
      "  [1 rows x 396 columns]                                                         ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'DataFrame'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9645/2856601915.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#pca = PCA(n_components=3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprincipalComponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m#print(principalComponents[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#print(pca.explained_variance_ratio_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \"\"\"\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    428\u001b[0m             )\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    431\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib64/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m/usr/local/lib64/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "data = dataset_cleaned_train_features\n",
    "work = data.copy()\n",
    "targets = pd.DataFrame(work[[\"gesture\",\"subject\",\"sample\"]], columns=[\"gesture\",\"subject\",\"sample\"])\n",
    "targets.reset_index(inplace=True, drop=True)\n",
    "target_for_plot = pd.DataFrame(work[[\"gesture\"]], columns=[\"gesture\"])\n",
    "target_for_plot.reset_index(inplace=True, drop=True)\n",
    "work = work.drop(labels = [\"gesture\",\"subject\", \"sample\"], axis = 1)\n",
    "print(work.values)\n",
    "\n",
    "#pca = PCA(n_components=3)\n",
    "pca = PCA(.99)\n",
    "principalComponents = pca.fit_transform(work)\n",
    "#print(principalComponents[0])\n",
    "#print(pca.explained_variance_ratio_)\n",
    "#total = 0\n",
    "#for tmp in pca.explained_variance_ratio_:\n",
    "#    total += tmp\n",
    "#print(total)\n",
    "print(pca.n_features_)\n",
    "print(pca.n_samples_)\n",
    "#print(pca.noise_variance_)\n",
    "print(pca.n_components_)\n",
    "#print(pca.components_)\n",
    "\n",
    "columns = []\n",
    "for i in range(pca.n_components_):\n",
    "    columns.append(\"principal component \"+str(i+1))\n",
    "features_pca = pd.DataFrame(data = principalComponents, columns = columns)\n",
    "features_pca = pd.concat([features_pca, targets], axis = 1)\n",
    "features_pca_for_plot = pd.DataFrame(data = principalComponents, columns = columns)\n",
    "features_pca_for_plot = pd.concat([features_pca_for_plot, target_for_plot], axis = 1)\n",
    "\n",
    "fig = plt.figure(figsize = (70,70))\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\");\n",
    "#sns.pairplot(iris, hue = \"species\", size = 3);\n",
    "#plt.show()\n",
    "# NOTE: the diagonal elements are PDFs for each feature.import seaborn as sns\n",
    "sns.pairplot(features_pca_for_plot, hue='gesture')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61999f8b-8d0f-41ef-978a-be8384dcb928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
